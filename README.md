# Estagio_CBL_DS
Prot√≥tipo de pipeline de dados (ETL/ELT) desenvolvido com Python, Pandas, SQL e GIT, seguindo a metodologia Challenge-Based Learning (CBL) para est√°gio em Ci√™ncia de Dados.

# üöÄ Fase 1: Engajamento (Big Idea & Essential Question)
Definir o escopo do desafio de aprendizado, alinhando-o com os objetivos da vaga.

Ideia Central (Big Idea)
"O Valor dos Dados: Como os Dados Brutos s√£o Transformados em Insights Acion√°veis e Conhecimento Estrat√©gico para a Empresa."

Pergunta Essencial (Essential Question)
"Como posso desenvolver um fluxo de trabalho de ponta a ponta em Python, utilizando pr√°ticas de engenharia de software (Git), para transformar dados heterog√™neos em um dataset limpo e pronto para an√°lise, gerando um insight estrat√©gico que promova uma melhoria processual na √°rea de atua√ß√£o?"

O Desafio (Challenge)
"Construir um mini-pipeline de ETL (Extra√ß√£o, Transforma√ß√£o e Carga) para processar dados de vendas (simulados: CSV, JSON, consulta SQL) e gerar um painel de indicadores (dashboard) simples em Python, que revele a principal 'dor' ou oportunidade de otimiza√ß√£o de processo na opera√ß√£o de uma empresa hipot√©tica (ex: log√≠stica, marketing)."


# üî¨ Fase 2: Investiga√ß√£o (Learning Resources & Activities) 
Esta √© a fase de aquisi√ß√£o de conhecimento e desenvolvimento das habilidades necess√°rias para superar o Desafio.

T√≥pico (Habilidade):
- Python Intermedi√°rio (Scripts e Automa√ß√£o) 

- Processamento de M√∫ltiplas Fontes (ETL)

- GIT para Controle de Vers√£o

- Organiza√ß√£o e Documenta√ß√£o

- Extra√ß√£o de Insights e Relat√≥rios


Atividades de Estudo Recomendadas:
- Estruturas de Dados Avan√ßadas: Foco em Dicion√°rios, List Comprehensions, e itertools.

- Pandas: Dominar read_csv, read_json, merge, groupby, apply, e tratamento de valores ausentes (NaN).

- Fun√ß√µes e Classes: Praticar a escrita de scripts modulares e reutiliz√°veis (automa√ß√£o de tarefas).

- Extra√ß√£o de APIs: Praticar requisi√ß√µes HTTP (biblioteca requests) para obter dados em formato JSON.

- SQL B√°sico: Foco em SELECT, FROM, WHERE, JOIN (consultas simples). Usar um banco de dados local (ex: SQLite).

- Leitura/Escrita de Arquivos: Praticar a manipula√ß√£o de caminhos e formatos (os, pathlib).

- Comandos Essenciais: Dominar init, clone, add, commit, push, pull, branch, e merge.

- Fluxo de Trabalho: Praticar o trabalho com branches (desenvolvimento em feature branches e merge para main).

- Boas Pr√°ticas: Aprender a usar docstrings (documenta√ß√£o de fun√ß√µes), coment√°rios claros e type hinting.

- Estrutura de Projeto: Organizar o c√≥digo em pastas l√≥gicas (src, data, notebooks).

- Visualiza√ß√£o B√°sica: Utilizar matplotlib e seaborn (ou Plotly) para criar gr√°ficos que contem uma hist√≥ria sobre os dados.

- Estat√≠stica Descritiva: Calcular m√©dias, medianas, desvios e identificar outliers.


Recursos de Aprendizagem Sugeridos:
- Cursos online (DataCamp, Coursera) com foco em Pandas.

- Pr√°tica no Kaggle (limpeza de dados).

- Livros/Documenta√ß√£o do Python sobre estruturas e bibliotecas padr√µes.

- Tutoriais sobre a biblioteca requests e json no Python.

- Exerc√≠cios pr√°ticos de SQL online (SQL Zoo, HackerRank).

- Projetos que simulem a leitura de dados de CSV, JSON e DB ao mesmo tempo.

- Curso b√°sico de Git e GitHub (ex: FreeCodeCamp, Alura).

- Utilizar Git em todos os projetos de Python desenvolvidos na Fase 2.

- Guias de estilo de c√≥digo (ex: PEP 8).

- Leitura sobre melhores pr√°ticas de documenta√ß√£o de c√≥digo em Python.

- Tutoriais de visualiza√ß√£o de dados em Python (foco em comunica√ß√£o clara).

- An√°lise de datasets de exemplo (ex: dados de vendas) para encontrar tend√™ncias.


# ‚ú® Fase 3: A√ß√£o (Solution Development & Reflection)
Aplica√ß√£o pr√°tica do conhecimento adquirido, culminando na solu√ß√£o do Desafio e reflex√£o sobre o aprendizado.

## Etapa 1: Desenvolver a Solu√ß√£o do Desafio

A√ß√£o: Constru√ß√£o do Mini-Pipeline de ETL


Extra√ß√£o (E):

Criar tr√™s fontes de dados simuladas: um CSV de pedidos, um JSON de informa√ß√µes do cliente (extra√≠do via simula√ß√£o de API), e um pequeno banco de dados SQLite com dados de estoque (consulta SQL b√°sica).


Transforma√ß√£o (T):

Escrever um script Python (usando Pandas) que leia, integre (merge), limpe (trate NaNs e formate tipos) e transforme os dados das tr√™s fontes em um dataset √∫nico e coerente.

Automa√ß√£o: Garantir que este processo seja executado por um √∫nico script modular.


Carga e An√°lise (L & Insights):

Carregar o dataset limpo em um arquivo final (ex: clean_data.csv).

Desenvolver o segundo script de an√°lise para extrair um insight claro (ex: "Qual a categoria de produto com maior margem, mas com o maior tempo m√©dio de entrega?") e gerar um gr√°fico de visualiza√ß√£o (relat√≥rio simples).


Controle de Vers√£o:

Usar o Git desde o in√≠cio, para criar branches para a extra√ß√£o, transforma√ß√£o e an√°lise, e fazer commits regulares e detalhados.


## Etapa 2: Compartilhamento e Documenta√ß√£o

Documenta√ß√£o: Escrever um README.md claro no reposit√≥rio Git, explicando o prop√≥sito do projeto, como executar o script (instru√ß√µes), e o insight final encontrado.

Organiza√ß√£o: Organizar o reposit√≥rio seguindo a Estrutura de Projeto (ex: /src para scripts, /data para dados brutos e limpos).


## Etapa 3: Reflex√£o (Otimiza√ß√£o e Melhoria)

Responder √†s seguintes perguntas para consolidar o aprendizado:

O que aprendi sobre lidar com tipos de dados conflitantes de m√∫ltiplas fontes? (Relacionado ao Processamento de Dados)

Onde o uso do Git me salvou de um problema? (Relacionado ao Controle de Vers√£o)

Como meu script de automa√ß√£o poderia ser melhorado para ser mais r√°pido ou robusto (ex: tratamento de erros)? (Relacionado √† Otimiza√ß√£o de Processos)

O insight gerado pode realmente levar a uma melhoria processual na empresa hipot√©tica? (Relacionado √† Extra√ß√£o de Insights e Alinhamento Estrat√©gico)

Este plano de estudo transforma as atividades e habilidades da vaga em um projeto pr√°tico e tang√≠vel apresentado no processo seletivo.
